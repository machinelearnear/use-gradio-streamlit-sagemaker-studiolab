{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53b74bb6-8659-490f-b0db-16bbc6babfa1",
   "metadata": {},
   "source": [
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/machinelearnear/use-gradio-streamlit-sagemaker-studiolab/blob/main/1_launch_gradio_streamlit.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261a11ab-2952-4901-a5ee-99a090dc13ed",
   "metadata": {},
   "source": [
    "# Use Gradio or Streamlit in SageMaker Studio Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca3a2f-a387-40a8-aa7a-028c3d433626",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b6b3355-2e36-4a6c-8296-5960f3b415c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4568332b-7641-4fe6-a1ee-b7b41587b62a",
   "metadata": {},
   "source": [
    "### Configure Studio Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f42126-3a34-4aef-bf71-29aee7243c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "studiolab_domain = 'luzdatd5d7fmka0'\n",
    "studiolab_region = 'us-east-2'\n",
    "studiolab_url = f'https://{studiolab_domain}.studio.{studiolab_region}.sagemaker.aws/studiolab/default/jupyter/proxy/6006/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d1854-cc62-44c5-a1f9-ef7a4f8e1a2b",
   "metadata": {},
   "source": [
    "## Launch application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa7a51-e9bb-4995-a353-0a3584fcafae",
   "metadata": {},
   "source": [
    "### Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d27d90d-2ccc-4432-964e-ba8174a9ab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait a few seconds and then click the link below to open your Gradio application \n",
      "https://luzdatd5d7fmka0.studio.us-east-2.sagemaker.aws/studiolab/default/jupyter/proxy/6006/\n",
      "2022-03-10 18:49:28.543899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-10 18:49:28.543933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Loading model...\n",
      "config.json not found in HuggingFace Hub\n",
      "2022-03-10 18:49:33.692177: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-10 18:49:33.692218: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-10 18:49:33.692242: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2022-03-10 18:49:33.692463: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Successfully loaded model...\n",
      "Using cache from '/home/studio-lab-user/use-gradio-streamlit-sagemaker-studiolab/gradio_cached_examples/' directory. If method or examples have changed since last caching, delete this folder to clear cache.\n",
      "Running on local URL:  http://127.0.0.1:6006/\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    }
   ],
   "source": [
    "print(f'Wait a few seconds and then click the link below to open your Gradio application \\n{studiolab_url}\\n')\n",
    "\n",
    "# launch\n",
    "!python app_gradio.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092616ee-b36a-47e5-9ba1-26abb676b69a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a8e30-390d-4c8f-a370-7553258f72cd",
   "metadata": {},
   "source": [
    "Following the same capability for `Tensorboard` on SageMaker Studio, you can now apply the same to work with a `Streamlit` application, except the default port (8051) set by `Streamlit` is not open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6d3a9-f9dc-47e1-bdc9-77dab76c7790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait a few seconds and then click the link below to open your Streamlit application \n",
      "https://luzdatd5d7fmka0.studio.us-east-2.sagemaker.aws/studiolab/default/jupyter/proxy/6006/\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://169.254.255.2:6006\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://3.132.111.50:6006\u001b[0m\n",
      "\u001b[0m\n",
      "2022-03-10 19:01:50.537394: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-10 19:01:50.537430: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "config.json not found in HuggingFace Hub\n",
      "2022-03-10 19:01:52.127 config.json not found in HuggingFace Hub\n",
      "config.json not found in HuggingFace Hub\n",
      "2022-03-10 19:01:52.446 config.json not found in HuggingFace Hub\n",
      "2022-03-10 19:01:53.424027: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-10 19:01:53.424070: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-10 19:01:53.424094: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2022-03-10 19:01:53.424324: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-10 19:02:46.528 Traceback (most recent call last):\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/streamlit/script_runner.py\", line 430, in _run_script\n",
      "    exec(code, module.__dict__)\n",
      "  File \"/home/studio-lab-user/use-gradio-streamlit-sagemaker-studiolab/app_streamlit.py\", line 135, in <module>\n",
      "    main()\n",
      "  File \"/home/studio-lab-user/use-gradio-streamlit-sagemaker-studiolab/app_streamlit.py\", line 51, in main\n",
      "    model = load_model() # first things, first.. load your model\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/streamlit/legacy_caching/caching.py\", line 573, in wrapped_func\n",
      "    return get_or_create_cached_value()\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/streamlit/legacy_caching/caching.py\", line 557, in get_or_create_cached_value\n",
      "    return_value = func(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/use-gradio-streamlit-sagemaker-studiolab/app_streamlit.py\", line 44, in load_model\n",
      "    model = from_pretrained_keras(keras_model, custom_objects=custom_objects, compile=False)\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/huggingface_hub/keras_mixin.py\", line 57, in from_pretrained_keras\n",
      "    return KerasModelHubMixin.from_pretrained(*args, **kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/huggingface_hub/hub_mixin.py\", line 155, in from_pretrained\n",
      "    return cls._from_pretrained(\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/huggingface_hub/keras_mixin.py\", line 231, in _from_pretrained\n",
      "    model = tf.keras.models.load_model(storage_folder, **model_kwargs)\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/studio-lab-user/.conda/envs/machinelearnear-gradio-streamlit/lib/python3.9/site-packages/tensorflow/python/saved_model/load.py\", line 977, in load_internal\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for /home/studio-lab-user/.cache/huggingface/hub/keras-io--monocular-depth-estimation.main.add378b9cf6ddf6e04ff4186b083cfb6022f27e9/variables/variables\n",
      " You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Wait a few seconds and then click the link below to open your Streamlit application \\n{studiolab_url}\\n')\n",
    "\n",
    "# launch\n",
    "!streamlit run app_streamlit.py --server.port 6006 # or 80/8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cebf8ad-9d61-42c5-9516-635511d11f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearnear-gradio-streamlit:Python",
   "language": "python",
   "name": "conda-env-machinelearnear-gradio-streamlit-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
